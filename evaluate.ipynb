{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:04.593492Z",
     "start_time": "2024-11-20T03:39:04.580497Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:05.366170Z",
     "start_time": "2024-11-20T03:39:05.359172Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:08.468426Z",
     "start_time": "2024-11-20T03:39:06.056554Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:12.094405Z",
     "start_time": "2024-11-20T03:39:08.472425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\lss666\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "\n",
    "from training import get_config, CIFAR10Dataset,ImgDataset\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:12.110403Z",
     "start_time": "2024-11-20T03:39:12.096405Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fid_score(test_loader, gen_loader, feature_dim=2048):\n",
    "    fid_metric = FrechetInceptionDistance(feature=feature_dim, normalize=True).to(device)\n",
    "\n",
    "    for (x_test, _) in tqdm(test_loader):\n",
    "        x_test = x_test.to(device)\n",
    "        # x_test= x_test.type(torch.uint8)\n",
    "        fid_metric.update(x_test, real=True)\n",
    "\n",
    "    for (x_gen, _) in tqdm(gen_loader):\n",
    "        x_gen = x_gen.to(device)\n",
    "        # x_gen= x_gen.type(torch.uint8)\n",
    "        fid_metric.update(x_gen, real=False)\n",
    "\n",
    "    fid_score = fid_metric.compute()\n",
    "    return fid_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:12.424049Z",
     "start_time": "2024-11-20T03:39:12.112403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\lss666\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "inception_metric = InceptionScore()\n",
    "\n",
    "def get_inception_score(gen_loader):\n",
    "    inception_metric = InceptionScore(normalize=True).to(device)\n",
    "    \n",
    "    for (x_gen, _) in tqdm(gen_loader):\n",
    "        x_gen = x_gen.to(device)\n",
    "        inception_metric.update(x_gen)\n",
    "        \n",
    "    inception_score = inception_metric.compute()\n",
    "    return inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:39:14.254352Z",
     "start_time": "2024-11-20T03:39:12.427580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_size': 32, 'channels': 3, 'batch_size': 512, 'train_transform': Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      "), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")}\n",
      "{'lr': 0.0002, 'timesteps': 100, 'epochs': 100, 'rounds': 20, 'local_epochs': 5, 'ema_decay': 0.998, 'eta': 1, 'save_interval': 10, 'start_step': 20}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define dataset.\n",
    "dataset_name = 'cifar_10'\n",
    "# dataset_name = 'fashion_mnist'\n",
    "#dataset_name = 'svhn'\n",
    "\n",
    "data_config, train_config = get_config(dataset_name)\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "\n",
    "# Data config.\n",
    "batch_size = 32\n",
    "test_transform = data_config['test_transform']\n",
    "\n",
    "# Training config.\n",
    "timesteps = train_config['timesteps']\n",
    "eta = train_config['eta']\n",
    "\n",
    "# Data.\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义数据转换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 与训练集保持一致\n",
    "])\n",
    "\n",
    "# 替换数据集加载方式\n",
    "data_dir = os.path.join('datasets', dataset_name)\n",
    "\n",
    "# 加载训练集\n",
    "train_data = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "# 加载测试集\n",
    "test_data = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T03:41:47.832540Z",
     "start_time": "2024-11-20T03:39:14.256352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:21<00:00, 19.19it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(264.7091, device='cuda:0')\n",
      "264.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:16<00:00, 19.21it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(265.2239, device='cuda:0')\n",
      "265.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:16<00:00, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.5137, device='cuda:0'), tensor(0.0119, device='cuda:0'))\n",
      "mean: 1.51, std: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name='cifar_10'\n",
    "centralized_gen_dir = os.path.join('./output/diffusion_cen/', dataset_name, 'generated_img')\n",
    "centralized_gen_data = ImgDataset(centralized_gen_dir, transform=test_transform)\n",
    "centralized_gen_loader = torch.utils.data.DataLoader(centralized_gen_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "cen_fid_score = get_fid_score(train_loader, centralized_gen_loader)\n",
    "print(cen_fid_score)\n",
    "print('{:.2f}'.format(cen_fid_score))\n",
    "\n",
    "cen_fid_score = get_fid_score(test_loader, centralized_gen_loader)\n",
    "print(cen_fid_score)\n",
    "print('{:.2f}'.format(cen_fid_score))\n",
    "\n",
    "cen_inception_score = get_inception_score(centralized_gen_loader)\n",
    "print(cen_inception_score)\n",
    "(mean, std) = cen_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T08:12:31.124753Z",
     "start_time": "2024-11-13T08:12:30.129860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/diffusion_fedavg/cifar_10_b_5_c_10_le_5\\generated_img\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './output/diffusion_fedavg/cifar_10_b_5_c_10_le_5\\\\generated_img'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m fedavg_gen_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./output/diffusion_fedavg/\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_b_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_c_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_le_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(dataset_name, beta, num_clients, num_local_epochs), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerated_img\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(fedavg_gen_dir)\n\u001B[1;32m----> 7\u001B[0m fedavg_gen_data \u001B[38;5;241m=\u001B[39m \u001B[43mCIFAR10Dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfedavg_gen_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_transform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m fedavg_gen_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(fedavg_gen_data, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m, prefetch_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m)\n\u001B[0;32m     10\u001B[0m fedavg_train_fid_score \u001B[38;5;241m=\u001B[39m get_fid_score(train_loader, fedavg_gen_loader)\n",
      "File \u001B[1;32mE:\\LSS\\federated_diffusion_model-main\\training.py:70\u001B[0m, in \u001B[0;36mCIFAR10Dataset.__init__\u001B[1;34m(self, parent_dir, label_idx_dict, transform)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_idx_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_count_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m---> 70\u001B[0m sub_dirs \u001B[38;5;241m=\u001B[39m [f\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparent_dir\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mis_dir()]\n\u001B[0;32m     71\u001B[0m sub_dirs\u001B[38;5;241m.\u001B[39msort()\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_idx_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: './output/diffusion_fedavg/cifar_10_b_5_c_10_le_5\\\\generated_img'"
     ]
    }
   ],
   "source": [
    "beta = 5                     # 5, 0.5, 0.1              \n",
    "num_clients = 10               # 10, 30, 50\n",
    "num_local_epochs = 5           # 1, 5, 10\n",
    "\n",
    "fedavg_gen_dir = os.path.join('./output/diffusion_fedavg/', '{}_b_{}_c_{}_le_{}'.format(dataset_name, beta, num_clients, num_local_epochs), 'generated_img')\n",
    "print(fedavg_gen_dir)\n",
    "fedavg_gen_data = CIFAR10Dataset(fedavg_gen_dir, transform=test_transform)\n",
    "fedavg_gen_loader = torch.utils.data.DataLoader(fedavg_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "fedavg_train_fid_score = get_fid_score(train_loader, fedavg_gen_loader)\n",
    "print(fedavg_train_fid_score)\n",
    "print('{:.2f}'.format(fedavg_train_fid_score))\n",
    "\n",
    "fedavg_test_fid_score = get_fid_score(test_loader, fedavg_gen_loader)\n",
    "print(fedavg_test_fid_score)\n",
    "print('{:.2f}'.format(fedavg_test_fid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-10T02:36:56.821785Z"
    }
   },
   "outputs": [],
   "source": [
    "fedavg_inception_score = get_inception_score(fedavg_gen_loader)\n",
    "print(fedavg_inception_score)\n",
    "(mean, std) = fedavg_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.303339Z"
    }
   },
   "outputs": [],
   "source": [
    "# imgs_dist1 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "# imgs_dist2 = torch.randint(100, 255, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "\n",
    "# imgs_dist1 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "# imgs_dist2 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "\n",
    "# fid = FrechetInceptionDistance(feature=64).to(device)\n",
    "# fid.update(imgs_dist1, real=True)\n",
    "# fid.update(imgs_dist2, real=False)\n",
    "# fid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FrechetInceptionDistance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.306337Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'sars_cov_2_ct_scan'\n",
    "\n",
    "data_config, train_config = get_config(dataset_name)\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "\n",
    "# Data config.\n",
    "batch_size = 96\n",
    "train_transform = data_config['train_transform']\n",
    "\n",
    "# Training config.\n",
    "timesteps = train_config['timesteps']\n",
    "eta = train_config['eta']\n",
    "\n",
    "data_dir = os.path.join('../datasets/', dataset_name)\n",
    "\n",
    "train_dir = os.path.join(data_dir)\n",
    "train_data = ImgDataset(train_dir, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.307337Z"
    }
   },
   "outputs": [],
   "source": [
    "centralized_gen_dir = os.path.join('./output/diffusion_cen/', dataset_name, 'generated_img')\n",
    "centralized_gen_data = ImgDataset(centralized_gen_dir, transform=train_transform)\n",
    "centralized_gen_loader = torch.utils.data.DataLoader(centralized_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "cen_fid_score = get_fid_score(train_loader, centralized_gen_loader)\n",
    "print(cen_fid_score)\n",
    "print('{:.2f}'.format(cen_fid_score))\n",
    "\n",
    "cen_inception_score = get_inception_score(centralized_gen_loader)\n",
    "print(cen_inception_score)\n",
    "(mean, std) = cen_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.309335Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = get_fid_score(fedavg_gen_loader, centralized_gen_loader)\n",
    "# print(test)\n",
    "# print('{:.2f}'.format(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.310335Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = 0.5                     # 5, 0.5, 0.1              \n",
    "num_clients = 10               # 10, 30, 50\n",
    "num_local_epochs = 5           # 1, 5, 10\n",
    "\n",
    "fedavg_gen_dir = os.path.join('./output/diffusion_fedavg/', '{}_b_{}_c_{}_le_{}'.format(dataset_name, beta, num_clients, num_local_epochs), 'generated_img')\n",
    "print(fedavg_gen_dir)\n",
    "fedavg_gen_data = ImgDataset(fedavg_gen_dir, transform=train_transform)\n",
    "fedavg_gen_loader = torch.utils.data.DataLoader(fedavg_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "fedavg_train_fid_score = get_fid_score(train_loader, fedavg_gen_loader)\n",
    "print(fedavg_train_fid_score)\n",
    "print('{:.2f}'.format(fedavg_train_fid_score))\n",
    "\n",
    "fedavg_inception_score = get_inception_score(fedavg_gen_loader)\n",
    "print(fedavg_inception_score)\n",
    "(mean, std) = fedavg_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.311337Z"
    }
   },
   "outputs": [],
   "source": [
    "fedavg_gen_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-08T08:32:25.314337Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
