{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:15.069149Z",
     "start_time": "2024-11-28T02:27:13.037490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:15.243751Z",
     "start_time": "2024-11-28T02:27:15.231752Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:15.668320Z",
     "start_time": "2024-11-28T02:27:15.651322Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:17.282921Z",
     "start_time": "2024-11-28T02:27:15.934321Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import DiffusionModel\n",
    "from training import get_config,CIFAR10Dataset,ema_update, demo, generate_img\n",
    "from diffusion import diffusion_loss\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:17.298920Z",
     "start_time": "2024-11-28T02:27:17.285919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset.\n",
    "dataset_name = 'cifar_10'\n",
    "# dataset_name = 'svhn'\n",
    "#dataset_name = 'fashion_mnist'\n",
    "\n",
    "save_dir = os.path.join('./output/diffusion_cen', dataset_name)\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:17.313921Z",
     "start_time": "2024-11-28T02:27:17.300921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_size': 32, 'channels': 3, 'batch_size': 512, 'train_transform': Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      "), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")}\n",
      "{'lr': 0.0002, 'timesteps': 100, 'epochs': 100, 'rounds': 20, 'local_epochs': 5, 'ema_decay': 0.998, 'eta': 1, 'save_interval': 10}\n"
     ]
    }
   ],
   "source": [
    "data_config, train_config = get_config(dataset_name)\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "\n",
    "# Data config.\n",
    "# img_size = data_config['img_size']\n",
    "# channels = data_config['channels']\n",
    "batch_size = data_config['batch_size']\n",
    "train_transform = data_config['train_transform']\n",
    "test_transform = data_config['test_transform']\n",
    "\n",
    "# Training config.\n",
    "lr = train_config['lr']\n",
    "timesteps = train_config['timesteps']\n",
    "num_epochs = train_config['epochs']\n",
    "ema_decay = train_config['ema_decay']\n",
    "eta = train_config['eta']\n",
    "save_interval = train_config['save_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:19.038082Z",
     "start_time": "2024-11-28T02:27:17.315920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data.\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义数据转换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 与训练集保持一致\n",
    "])\n",
    "\n",
    "# 替换数据集加载方式\n",
    "data_dir = os.path.join('datasets', dataset_name)\n",
    "\n",
    "# 加载训练集\n",
    "train_data = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "# 加载测试集\n",
    "test_data = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# 后续可以使用 train_loader 和 test_loader 进行训练和测试\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:19.054168Z",
     "start_time": "2024-11-28T02:27:19.041082Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:19.069696Z",
     "start_time": "2024-11-28T02:27:19.055698Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import torchvision.transforms.functional as F\n",
    "# import numpy as np\n",
    "\n",
    "# def show(imgs):\n",
    "#     if not isinstance(imgs, list):\n",
    "#         imgs = [imgs]\n",
    "#     fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "#     for i, img in enumerate(imgs):\n",
    "#         img = img.detach()\n",
    "#         img = F.to_pil_image(img)\n",
    "#         axs[0, i].imshow(np.asarray(img))\n",
    "#         axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        \n",
    "# img = test_data[1000][0]\n",
    "# show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:19.414122Z",
     "start_time": "2024-11-28T02:27:19.071781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model.\n",
    "model = DiffusionModel().to(device)\n",
    "model_ema = deepcopy(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "grad_scaler = torch.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:19.430122Z",
     "start_time": "2024-11-28T02:27:19.416126Z"
    }
   },
   "outputs": [],
   "source": [
    "# For logging model performance.\n",
    "metric_keys = ['train_loss', 'test_loss']\n",
    "performance_dict, performance_log = utils.get_performance_loggers(metric_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T02:27:19.732737Z",
     "start_time": "2024-11-28T02:27:19.431124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Automatic resuming from checkpoint.\n",
    "log_path = os.path.join(save_dir, 'performance_log.pickle')\n",
    "if os.path.isfile(log_path):\n",
    "    performance_log = utils.load_pickle(log_path)\n",
    "start_epoch = len(performance_log[metric_keys[0]])\n",
    "\n",
    "ckpt_path = os.path.join(save_dir, 'ckpt_bundle.pth')\n",
    "if start_epoch > 0:\n",
    "    ckpt_bundle = torch.load(ckpt_path, weights_only=True)\n",
    "    model.load_state_dict(ckpt_bundle['model'])\n",
    "    model_ema.load_state_dict(ckpt_bundle['model_ema'])\n",
    "    optimizer.load_state_dict(ckpt_bundle['optimizer'])\n",
    "    grad_scaler.load_state_dict(ckpt_bundle['grad_scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================== Epoch: 11 / 100 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 20/20 [00:03<00:00,  6.36it/s]\n",
      "train: 100%|██████████| 98/98 [00:26<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss :  0.0436767112767818\n",
      "test_loss :  0.04176629148423672\n",
      "\n",
      " ==================== Epoch: 12 / 100 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 20/20 [00:03<00:00,  6.54it/s]\n",
      "train: 100%|██████████| 98/98 [00:26<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss :  0.04315862382705114\n",
      "test_loss :  0.04117558840662241\n",
      "\n",
      " ==================== Epoch: 13 / 100 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 20/20 [00:03<00:00,  6.39it/s]\n",
      "train: 100%|██████████| 98/98 [00:26<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss :  0.04283940598216592\n",
      "test_loss :  0.04056508932262659\n",
      "\n",
      " ==================== Epoch: 14 / 100 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test:  85%|████████▌ | 17/20 [00:02<00:00,  6.26it/s]"
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    utils.print_separator(text='Epoch: {} / {}'.format(epoch + 1, num_epochs))\n",
    "    \n",
    "    # Evaluating.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with torch.random.fork_rng():\n",
    "            torch.manual_seed(seed)\n",
    "            rng = torch.quasirandom.SobolEngine(1, scramble=True)\n",
    "            for (x, y) in tqdm(test_loader, desc='test'):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                loss = diffusion_loss(model, x, y)\n",
    "                performance_dict['test_loss'].update_state(loss.item())\n",
    "                \n",
    "    # Training.\n",
    "    model.train()\n",
    "    for (x, y) in tqdm(train_loader, desc='train'):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Calculate loss.\n",
    "        loss = diffusion_loss(model, x, y)\n",
    "        performance_dict['train_loss'].update_state(loss.item())\n",
    "        \n",
    "        # Do the optimizer step and EMA update.\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        grad_scaler.step(optimizer)\n",
    "        ema_update(model, model_ema, 0.95 if epoch < 20 else ema_decay)\n",
    "        grad_scaler.update()\n",
    "        \n",
    "    # Save and print performance.\n",
    "    for key in metric_keys:\n",
    "        performance_log[key].append(performance_dict[key].result())\n",
    "        performance_dict[key].reset_state()\n",
    "        print(key, ': ',  performance_log[key][-1])\n",
    "        \n",
    "    if (epoch + 1) % save_interval == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, 'e_{}.pth'.format(str(epoch + 1).zfill(3))))\n",
    "        img_path = os.path.join(save_dir, 'demo_{}.png'.format(str(epoch + 1).zfill(3)))\n",
    "        demo(model, img_path, timesteps, eta)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    ckpt_bundle = {\n",
    "        'model': model.state_dict(),\n",
    "        'model_ema': model_ema.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'grad_scaler': grad_scaler.state_dict(),\n",
    "    }\n",
    "    torch.save(ckpt_bundle, ckpt_path)\n",
    "    utils.save_pickle(log_path, performance_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Plot training history.\n",
    "performance_log = utils.load_pickle(log_path)\n",
    "\n",
    "loss_plot_config = utils.LOSS_PLOT_CONFIG.copy()\n",
    "loss_plot_config['save_dir'] = os.path.join(save_dir, 'loss.png')\n",
    "loss_plot_config['show_img'] = True\n",
    "loss_plot_config['xlabel'] = 'epochs'\n",
    "loss_plot_config['labels'] = ['train', 'test']\n",
    "loss_plot_config['attributes'] = ['train_loss', 'test_loss']\n",
    "utils.save_history_plot(performance_log, loss_plot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-28T02:24:13.335456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload saved model for generation.\n",
    "# model = DiffusionModel().to(device)\n",
    "# model_ema = deepcopy(model)\n",
    "\n",
    "# save_bundle = torch.load(os.path.join(save_dir, 'e_{}.pth'.format(str(5).zfill(3))))\n",
    "# model.load_state_dict(save_bundle['model'])\n",
    "# model_ema.load_state_dict(save_bundle['model_ema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-28T02:24:13.336456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload saved model for generation.\n",
    "model = DiffusionModel().to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'e_{}.pth'.format('100'.zfill(3)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-28T02:24:13.337456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate and save image.\n",
    "img_path = os.path.join(save_dir, 'demo_final.png')\n",
    "# demo(model, img_path, timesteps, eta)\n",
    "demo(model, img_path, timesteps, eta, num_images=4, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save image.\n",
    "# img_path = os.path.join(save_dir, 'demo_final.png')\n",
    "# demo(model_ema, img_path, timesteps, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-28T02:24:13.340456Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate images for evaluation.\n",
    "idx_label_dict = {v: k for k, v in test_data.label_idx_dict.items()}\n",
    "for idx, label in idx_label_dict.items():\n",
    "     num_imgs = test_data.label_count_dict[label]\n",
    "     img_class = idx\n",
    "     class_dir = os.path.join(save_dir, 'generated_img', label)\n",
    "     os.makedirs(class_dir, exist_ok=True)\n",
    "     generate_img(model, class_dir, timesteps, eta, num_imgs, img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:50:00.853238Z",
     "start_time": "2024-11-20T04:50:00.838242Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1688637794.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[19], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    cfrom IPython.core.display import HTML\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cfrom IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T04:50:00.854239Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-20T04:50:00.856240Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
